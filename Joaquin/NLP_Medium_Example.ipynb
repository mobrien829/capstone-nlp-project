{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London (GPE)\n",
      "England (GPE)\n",
      "the United Kingdom (GPE)\n",
      "the River Thames (LOC)\n",
      "Great Britain (GPE)\n",
      "London (GPE)\n",
      "two millennia (DATE)\n",
      "Romans (NORP)\n",
      "Londinium (ORG)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the large English NLP model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# The text we want to examine\n",
    "text = \"\"\"London is the capital and most populous city of England and \n",
    "the United Kingdom.  Standing on the River Thames in the south east \n",
    "of the island of Great Britain, London has been a major settlement \n",
    "for two millennia. It was founded by the Romans, who named it Londinium.\n",
    "\"\"\"\n",
    "\n",
    "# Parse the text with spaCy. This runs the entire pipeline.\n",
    "doc = nlp(text)\n",
    "\n",
    "# 'doc' now contains a parsed version of text. We can use it to do anything we want!\n",
    "# For example, this will print out all the named entities that were detected:\n",
    "for entity in doc.ents:\n",
    "    print(f\"{entity.text} ({entity.label_})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.span.Span' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tokens)\n\u001b[1;32m     15\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124mIn 1950, Alan Turing published his famous article \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing Machinery and Intelligence\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. In 1957, Noam Chomsky’s \u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mSyntactic Structures revolutionized Linguistics with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniversal grammar\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, a rule based system of syntactic structures.\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mscrub\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mscrub\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      9\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(text)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39ments:\n\u001b[0;32m---> 11\u001b[0m     \u001b[43ment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m()\n\u001b[1;32m     12\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(replace_name_with_placeholder, doc)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tokens)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.span.Span' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "def replace_name_with_placeholder(token):\n",
    "    if token.ent_iob != 0 and token.ent_type_ == \"PERSON\":\n",
    "        return \"[REDACTED] \"\n",
    "    else:\n",
    "        return token.string\n",
    "\n",
    "# Loop through all the entities in a document and check if they are names\n",
    "def scrub(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        ent.merge()\n",
    "    tokens = map(replace_name_with_placeholder, doc)\n",
    "    return \"\".join(tokens)\n",
    "\n",
    "s = \"\"\"\n",
    "In 1950, Alan Turing published his famous article \"Computing Machinery and Intelligence\". In 1957, Noam Chomsky’s \n",
    "Syntactic Structures revolutionized Linguistics with 'universal grammar', a rule based system of syntactic structures.\n",
    "\"\"\"\n",
    "\n",
    "print(scrub(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
